{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9B_EK4Me9ix"
      },
      "outputs": [],
      "source": [
        "# Q1: The Probability Mass Function (PMF) is used for discrete random variables and gives the probability that a discrete random variable takes a particular value.\n",
        "# Example: Rolling a fair die, where the probability of each outcome (1, 2, 3, 4, 5, 6) is 1/6.\n",
        "# The Probability Density Function (PDF) is used for continuous random variables and describes the likelihood of a random variable taking a value within a given range.\n",
        "# Example: In a normal distribution, the PDF represents the probability of a random variable falling within a specific range of values, such as between 4 and 6.\n",
        "\n",
        "# Q2: The Cumulative Distribution Function (CDF) gives the probability that a random variable is less than or equal to a specific value.\n",
        "# Example: In a normal distribution, the CDF at value 1 will give the probability that a random value from the distribution is less than or equal to 1.\n",
        "# CDF is useful because it provides the cumulative probability for values less than or equal to a given point, helping to evaluate the likelihood of an event occurring within a range.\n",
        "\n",
        "# Q3: The normal distribution can model:\n",
        "# - Heights of people in a population (e.g., most people cluster around the mean, with fewer people at the extremes).\n",
        "# - IQ scores of a population.\n",
        "# - Test scores from large groups of students.\n",
        "# Parameters of the normal distribution:\n",
        "# - Mean (μ) determines the central peak of the distribution.\n",
        "# - Standard deviation (σ) affects the spread of the distribution: the larger the σ, the wider the distribution.\n",
        "\n",
        "# Q4: The importance of the Normal Distribution:\n",
        "# - Many real-world phenomena (e.g., heights, test scores, etc.) follow a normal distribution.\n",
        "# - It is the foundation for many statistical analyses, including hypothesis testing and confidence intervals.\n",
        "# Real-life examples:\n",
        "# 1. Human body temperatures (close to 98.6°F).\n",
        "# 2. Blood pressure in a population.\n",
        "# 3. Academic test scores (e.g., SAT, GRE scores).\n",
        "\n",
        "# Q5: The Bernoulli Distribution describes a single experiment with two possible outcomes: success (1) or failure (0).\n",
        "# Example: A coin flip, where heads = success (1) and tails = failure (0).\n",
        "# Difference between Bernoulli and Binomial Distribution:\n",
        "# - Bernoulli: Only one trial.\n",
        "# - Binomial: Multiple independent trials, each with two outcomes.\n",
        "\n",
        "# Q6: To calculate the probability of a value greater than 60 in a normal distribution with mean = 50 and standard deviation = 10:\n",
        "# First, calculate the z-score using the formula: z = (X - μ) / σ\n",
        "# For X = 60, z = (60 - 50) / 10 = 1.\n",
        "# Using a z-table or Python, we find that P(Z < 1) ≈ 0.8413, so P(X > 60) = 1 - 0.8413 ≈ 0.1587.\n",
        "\n",
        "# Q7: Uniform Distribution is a probability distribution where every outcome in a given range is equally likely.\n",
        "# Example: A fair die roll, where each face (1 through 6) has an equal probability of 1/6.\n",
        "\n",
        "# Q8: The z-score measures how many standard deviations a data point is from the mean of the dataset.\n",
        "# The formula is: z = (X - μ) / σ\n",
        "# Importance: The z-score helps in standardizing data, making it easier to compare different datasets or detect outliers. It also plays a key role in hypothesis testing.\n",
        "\n",
        "# Q9: The Central Limit Theorem (CLT) states that the sampling distribution of the sample mean will approach a normal distribution as the sample size increases, regardless of the original distribution.\n",
        "# Significance: This theorem is crucial because it allows for the use of normal distribution approximations even when the original data is not normally distributed, simplifying statistical analysis.\n",
        "\n",
        "# Q10: Assumptions of the Central Limit Theorem:\n",
        "# 1. The sample size should be sufficiently large (n ≥ 30).\n",
        "# 2. The samples must be independent.\n",
        "# 3. The population should have a finite variance.\n"
      ]
    }
  ]
}